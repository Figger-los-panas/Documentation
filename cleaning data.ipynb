{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiP9TniJo2j2",
        "outputId": "7fb361c5-7723-4453-ce8c-1d07c83e1022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (3.10.3)\n",
            "Requirement already satisfied: seaborn in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from pandas) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\documents\\lol\\bootcamp\\hackaton\\documentation\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas matplotlib seaborn scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d5-l5hBgpBue"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k_US1sLDpF3W"
      },
      "outputs": [],
      "source": [
        "testing = pd.read_csv(\"Dataset_Talento.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWMSjCoGrAWV",
        "outputId": "268d50d5-ebf6-402d-8e5b-f43ca9f00b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 18 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   timestamp              6000 non-null   object \n",
            " 1   turno                  6000 non-null   object \n",
            " 2   operador_id            6000 non-null   object \n",
            " 3   maquina_id             6000 non-null   object \n",
            " 4   producto_id            6000 non-null   object \n",
            " 5   temperatura            5820 non-null   float64\n",
            " 6   vibración              5820 non-null   float64\n",
            " 7   humedad                5820 non-null   float64\n",
            " 8   tiempo_ciclo           5820 non-null   float64\n",
            " 9   fallo_detectado        6000 non-null   object \n",
            " 10  tipo_fallo             599 non-null    object \n",
            " 11  cantidad_producida     6000 non-null   int64  \n",
            " 12  unidades_defectuosas   6000 non-null   int64  \n",
            " 13  eficiencia_porcentual  5820 non-null   float64\n",
            " 14  consumo_energia        5820 non-null   float64\n",
            " 15  paradas_programadas    6000 non-null   int64  \n",
            " 16  paradas_imprevistas    6000 non-null   int64  \n",
            " 17  observaciones          1774 non-null   object \n",
            "dtypes: float64(6), int64(4), object(8)\n",
            "memory usage: 843.9+ KB\n"
          ]
        }
      ],
      "source": [
        "testing.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhgc57x-pPLl"
      },
      "source": [
        "\n",
        "<br><br>\n",
        "<br>\n",
        "Modulo de limpieza\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEVYgJcNpO-W",
        "outputId": "462c8090-3dbd-4c4c-e554-bb6760ebc496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATA CLEANING: REMOVING ROWS WITH NaN IN SPECIFIC COLUMNS ===\n",
            "\n",
            "Critical columns (cannot have NaN): ['temperatura', 'vibración', 'humedad', 'tiempo_ciclo', 'eficiencia_porcentual', 'consumo_energia']\n",
            "============================================================\n",
            "Initial dataset: 6000 rows\n",
            "\n",
            "Found critical columns: ['temperatura', 'vibración', 'humedad', 'tiempo_ciclo', 'eficiencia_porcentual', 'consumo_energia']\n",
            "\n",
            "NaN count in critical columns BEFORE cleaning:\n",
            "  temperatura: 180 NaN values\n",
            "  vibración: 180 NaN values\n",
            "  humedad: 180 NaN values\n",
            "  tiempo_ciclo: 180 NaN values\n",
            "  eficiencia_porcentual: 180 NaN values\n",
            "  consumo_energia: 180 NaN values\n",
            "\n",
            "CLEANING RESULTS:\n",
            "========================================\n",
            "Rows before cleaning: 6000\n",
            "Rows after cleaning:  4991\n",
            "Rows removed:         1009\n",
            "Data retention:       83.2%\n",
            "\n",
            "================================================================================\n",
            "DATASET INFO AFTER CLEANING:\n",
            "================================================================================\n",
            " 1. timestamp                 | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            " 2. turno                     | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            " 3. operador_id               | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            " 4. maquina_id                | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            " 5. producto_id               | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            " 6. temperatura               | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            " 7. vibración                 | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            " 8. humedad                   | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            " 9. tiempo_ciclo              | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            "10. fallo_detectado           | object     | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            "11. tipo_fallo                | object     |  495/4991 non-null | 4496 NaN ( 90.1%)\n",
            "12. cantidad_producida        | int64      | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            "13. unidades_defectuosas      | int64      | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            "14. eficiencia_porcentual     | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            "15. consumo_energia           | float64    | 4991/4991 non-null |   0 NaN (  0.0%) ★\n",
            "16. paradas_programadas       | int64      | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            "17. paradas_imprevistas       | int64      | 4991/4991 non-null |   0 NaN (  0.0%)\n",
            "18. observaciones             | object     | 1484/4991 non-null | 3507 NaN ( 70.3%)\n"
          ]
        }
      ],
      "source": [
        "testing = pd.read_csv(\"Dataset_Talento.csv\")\n",
        "\n",
        "print(\"=== DATA CLEANING: REMOVING ROWS WITH NaN IN SPECIFIC COLUMNS ===\\n\")\n",
        "\n",
        "# Define the columns that cannot have NaN values\n",
        "critical_columns = ['temperatura', 'vibración', 'humedad', 'tiempo_ciclo', 'eficiencia_porcentual', 'consumo_energia']\n",
        "\n",
        "print(f\"Critical columns (cannot have NaN): {critical_columns}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get initial dataset info\n",
        "initial_rows = len(testing)\n",
        "print(f\"Initial dataset: {initial_rows} rows\")\n",
        "\n",
        "# Check which critical columns exist in the dataset\n",
        "existing_critical_cols = [col for col in critical_columns if col in testing.columns]\n",
        "missing_critical_cols = [col for col in critical_columns if col not in testing.columns]\n",
        "\n",
        "print(f\"\\nFound critical columns: {existing_critical_cols}\")\n",
        "if missing_critical_cols:\n",
        "    print(f\"Missing critical columns: {missing_critical_cols}\")\n",
        "\n",
        "# Show NaN count in critical columns before cleaning\n",
        "print(f\"\\nNaN count in critical columns BEFORE cleaning:\")\n",
        "for col in existing_critical_cols:\n",
        "    nan_count = testing[col].isna().sum()\n",
        "    print(f\"  {col}: {nan_count} NaN values\")\n",
        "\n",
        "# Remove rows with NaN in any of the existing critical columns\n",
        "if existing_critical_cols:\n",
        "    testing_clean = testing.dropna(subset=existing_critical_cols).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"No critical columns found in dataset - no cleaning performed\")\n",
        "    testing_clean = testing.copy()\n",
        "\n",
        "# Calculate cleaning results\n",
        "final_rows = len(testing_clean)\n",
        "removed_rows = initial_rows - final_rows\n",
        "\n",
        "print(f\"\\nCLEANING RESULTS:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Rows before cleaning: {initial_rows}\")\n",
        "print(f\"Rows after cleaning:  {final_rows}\")\n",
        "print(f\"Rows removed:         {removed_rows}\")\n",
        "print(f\"Data retention:       {(final_rows/initial_rows*100):.1f}%\")\n",
        "\n",
        "# Show overall dataset info after cleaning\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATASET INFO AFTER CLEANING:\")\n",
        "print(\"=\" * 80)\n",
        "for i, col in enumerate(testing_clean.columns, 1):\n",
        "    dtype = testing_clean[col].dtype\n",
        "    non_null = testing_clean[col].count()\n",
        "    total = len(testing_clean)\n",
        "    null_count = total - non_null\n",
        "    null_pct = (null_count/total*100) if total > 0 else 0\n",
        "\n",
        "    # Mark critical columns\n",
        "    marker = \" ★\" if col in existing_critical_cols else \"\"\n",
        "\n",
        "    print(f\"{i:2d}. {col:25s} | {str(dtype):10s} | {non_null:4d}/{total} non-null | {null_count:3d} NaN ({null_pct:5.1f}%){marker}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvOVcgNMs0Hr",
        "outputId": "acda2c64-29ba-47c4-8eb4-703eed15da7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4991 entries, 0 to 4990\n",
            "Data columns (total 18 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   timestamp              4991 non-null   object \n",
            " 1   turno                  4991 non-null   object \n",
            " 2   operador_id            4991 non-null   object \n",
            " 3   maquina_id             4991 non-null   object \n",
            " 4   producto_id            4991 non-null   object \n",
            " 5   temperatura            4991 non-null   float64\n",
            " 6   vibración              4991 non-null   float64\n",
            " 7   humedad                4991 non-null   float64\n",
            " 8   tiempo_ciclo           4991 non-null   float64\n",
            " 9   fallo_detectado        4991 non-null   object \n",
            " 10  tipo_fallo             495 non-null    object \n",
            " 11  cantidad_producida     4991 non-null   int64  \n",
            " 12  unidades_defectuosas   4991 non-null   int64  \n",
            " 13  eficiencia_porcentual  4991 non-null   float64\n",
            " 14  consumo_energia        4991 non-null   float64\n",
            " 15  paradas_programadas    4991 non-null   int64  \n",
            " 16  paradas_imprevistas    4991 non-null   int64  \n",
            " 17  observaciones          1484 non-null   object \n",
            "dtypes: float64(6), int64(4), object(8)\n",
            "memory usage: 702.0+ KB\n"
          ]
        }
      ],
      "source": [
        "testing_clean.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Xznr_-tLYS"
      },
      "source": [
        "<br>\n",
        "Testing cositas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aJVNPLVctOHa"
      },
      "outputs": [],
      "source": [
        "testing = testing_clean.copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gMplORhuu7Oe",
        "outputId": "66ff356d-8083-441e-b873-a3beba3757eb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Convert timestamp to datetime and extract time-based features\n",
        "testing_clean['timestamp'] = pd.to_datetime(testing_clean['timestamp'])\n",
        "testing_clean['hour'] = testing_clean['timestamp'].dt.hour\n",
        "testing_clean['day_of_week'] = testing_clean['timestamp'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
        "testing_clean['day_of_month'] = testing_clean['timestamp'].dt.day\n",
        "testing_clean['month'] = testing_clean['timestamp'].dt.month\n",
        "testing_clean['minute'] = testing_clean['timestamp'].dt.minute\n",
        "\n",
        "# Select numerical columns for correlation analysis (only from cleaned data)\n",
        "available_numerical_cols = []\n",
        "potential_cols = ['temperatura', 'vibración', 'humedad', 'tiempo_ciclo',\n",
        "                  'cantidad_producida', 'unidades_defectuosas',\n",
        "                  'eficiencia_porcentual', 'consumo_energia',\n",
        "                  'paradas_programadas', 'paradas_imprevistas']\n",
        "\n",
        "for col in potential_cols:\n",
        "    if col in testing_clean.columns:\n",
        "        available_numerical_cols.append(col)\n",
        "\n",
        "print(f\"Available numerical columns for analysis: {available_numerical_cols}\")\n",
        "\n",
        "# Time-based features to analyze\n",
        "time_features = ['hour', 'day_of_week', 'day_of_month', 'month', 'minute']\n",
        "\n",
        "print(\"\\n=== TIME-BASED CORRELATION ANALYSIS ON CLEANED DATA ===\\n\")\n",
        "print(\"Analyzing relationships between time features and manufacturing variables\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Analyze each time feature\n",
        "for time_feature in time_features:\n",
        "    print(f\"\\n{'='*20} {time_feature.upper()} ANALYSIS {'='*20}\")\n",
        "\n",
        "    correlations = []\n",
        "    for col in available_numerical_cols:\n",
        "        # Remove NaN values for pairwise correlation\n",
        "        valid_data = testing_clean[[time_feature, col]].dropna()\n",
        "\n",
        "        if len(valid_data) > 0:\n",
        "            # Pearson correlation\n",
        "            pearson_corr, pearson_p = pearsonr(valid_data[time_feature], valid_data[col])\n",
        "\n",
        "            # Spearman correlation (for non-linear relationships)\n",
        "            spearman_corr, spearman_p = spearmanr(valid_data[time_feature], valid_data[col])\n",
        "\n",
        "            correlations.append({\n",
        "                'Variable': col,\n",
        "                'Pearson_Corr': pearson_corr,\n",
        "                'Pearson_p_value': pearson_p,\n",
        "                'Spearman_Corr': spearman_corr,\n",
        "                'Spearman_p_value': spearman_p,\n",
        "                'Sample_Size': len(valid_data)\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and sort by correlation strength\n",
        "    corr_df = pd.DataFrame(correlations)\n",
        "    if len(corr_df) > 0:\n",
        "        corr_df = corr_df.sort_values('Pearson_Corr', key=abs, ascending=False)\n",
        "\n",
        "        print(f\"\\nCorrelations with {time_feature}:\")\n",
        "        print(\"-\" * 60)\n",
        "        for _, row in corr_df.iterrows():\n",
        "            significance = \"***\" if row['Pearson_p_value'] < 0.001 else \"**\" if row['Pearson_p_value'] < 0.01 else \"*\" if row['Pearson_p_value'] < 0.05 else \"\"\n",
        "            print(f\"{row['Variable']:20s} | r={row['Pearson_Corr']:6.3f} {significance:3s} | p={row['Pearson_p_value']:.3f}\")\n",
        "\n",
        "        # Identify significant relationships\n",
        "        significant_relations = corr_df[corr_df['Pearson_p_value'] < 0.05]\n",
        "\n",
        "        if len(significant_relations) > 0:\n",
        "            print(f\"\\nSignificant relationships with {time_feature}:\")\n",
        "            for _, row in significant_relations.iterrows():\n",
        "                strength = \"Strong\" if abs(row['Pearson_Corr']) > 0.3 else \"Moderate\" if abs(row['Pearson_Corr']) > 0.2 else \"Weak\"\n",
        "                direction = \"increases\" if row['Pearson_Corr'] > 0 else \"decreases\"\n",
        "\n",
        "                print(f\"• {row['Variable']}: {strength} - as {time_feature} increases, {row['Variable']} {direction}\")\n",
        "                print()\n",
        "    else:\n",
        "        print(f\"No numerical variables available for {time_feature} analysis\")\n",
        "\n",
        "# Create comprehensive time-based visualizations (only for available columns)\n",
        "if len(available_numerical_cols) > 0:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    plot_idx = 0\n",
        "\n",
        "    # Hour-based analysis for key variables\n",
        "    if 'eficiencia_porcentual' in available_numerical_cols:\n",
        "        ax = axes[plot_idx]\n",
        "        hourly_efficiency = testing_clean.groupby('hour')['eficiencia_porcentual'].mean().reset_index()\n",
        "        ax.plot(hourly_efficiency['hour'], hourly_efficiency['eficiencia_porcentual'], 'b-o', linewidth=2)\n",
        "        ax.set_xlabel('Hour of Day')\n",
        "        ax.set_ylabel('Efficiency %')\n",
        "        ax.set_title('Efficiency by Hour of Day')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "\n",
        "    # Production by day of week\n",
        "    if 'cantidad_producida' in available_numerical_cols:\n",
        "        ax = axes[plot_idx]\n",
        "        dow_production = testing_clean.groupby('day_of_week')['cantidad_producida'].mean().reset_index()\n",
        "        ax.bar(dow_production['day_of_week'], dow_production['cantidad_producida'], alpha=0.7)\n",
        "        ax.set_xlabel('Day of Week (0=Mon, 6=Sun)')\n",
        "        ax.set_ylabel('Average Production')\n",
        "        ax.set_title('Production by Day of Week')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "\n",
        "    # Temperature by hour (if available)\n",
        "    if 'temperatura' in available_numerical_cols:\n",
        "        ax = axes[plot_idx]\n",
        "        temp_hourly = testing_clean.groupby('hour')['temperatura'].mean().reset_index()\n",
        "        ax.plot(temp_hourly['hour'], temp_hourly['temperatura'], 'r-o', linewidth=2)\n",
        "        ax.set_xlabel('Hour of Day')\n",
        "        ax.set_ylabel('Temperature')\n",
        "        ax.set_title('Temperature by Hour of Day')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plot_idx += 1\n",
        "\n",
        "    # Fill remaining plots with other available variables\n",
        "    remaining_vars = ['consumo_energia', 'unidades_defectuosas', 'tiempo_ciclo']\n",
        "    for var in remaining_vars:\n",
        "        if var in available_numerical_cols and plot_idx < 6:\n",
        "            ax = axes[plot_idx]\n",
        "            var_hourly = testing_clean.groupby('hour')[var].mean().reset_index()\n",
        "            ax.plot(var_hourly['hour'], var_hourly[var], 'g-o', linewidth=2)\n",
        "            ax.set_xlabel('Hour of Day')\n",
        "            ax.set_ylabel(var.replace('_', ' ').title())\n",
        "            ax.set_title(f'{var.replace(\"_\", \" \").title()} by Hour of Day')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            plot_idx += 1\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for i in range(plot_idx, 6):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Manufacturing Performance Over Time (Cleaned Data)', fontsize=16, y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "# Summary statistics by time periods\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TIME-BASED PERFORMANCE SUMMARY (CLEANED DATA):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Peak performance hours (if efficiency data available)\n",
        "if 'eficiencia_porcentual' in available_numerical_cols:\n",
        "    efficiency_by_hour = testing_clean.groupby('hour')['eficiencia_porcentual'].mean()\n",
        "    best_hour = efficiency_by_hour.idxmax()\n",
        "    worst_hour = efficiency_by_hour.idxmin()\n",
        "    print(f\"Best efficiency hour: {best_hour}:00 ({efficiency_by_hour[best_hour]:.2f}%)\")\n",
        "    print(f\"Worst efficiency hour: {worst_hour}:00 ({efficiency_by_hour[worst_hour]:.2f}%)\")\n",
        "\n",
        "# Day of week patterns (if production data available)\n",
        "if 'cantidad_producida' in available_numerical_cols:\n",
        "    production_by_dow = testing_clean.groupby('day_of_week')['cantidad_producida'].mean()\n",
        "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    best_day = production_by_dow.idxmax()\n",
        "    worst_day = production_by_dow.idxmin()\n",
        "    print(f\"Best production day: {days[best_day]} ({production_by_dow[best_day]:.2f} units)\")\n",
        "    print(f\"Worst production day: {days[worst_day]} ({production_by_dow[worst_day]:.2f} units)\")\n",
        "\n",
        "# Quality patterns (if defect data available)\n",
        "if 'unidades_defectuosas' in available_numerical_cols:\n",
        "    defects_by_dow = testing_clean.groupby('day_of_week')['unidades_defectuosas'].mean()\n",
        "    best_quality_day = defects_by_dow.idxmin()\n",
        "    worst_quality_day = defects_by_dow.idxmax()\n",
        "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    print(f\"Best quality day: {days[best_quality_day]} ({defects_by_dow[best_quality_day]:.2f} defects)\")\n",
        "    print(f\"Worst quality day: {days[worst_quality_day]} ({defects_by_dow[worst_quality_day]:.2f} defects)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "298     101.573110\n",
              "693     100.179076\n",
              "1957    102.024829\n",
              "2053    101.016465\n",
              "4300    100.520575\n",
              "Name: eficiencia_porcentual, dtype: float64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_clean[testing_clean['eficiencia_porcentual'] > 100]['eficiencia_porcentual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], Name: eficiencia_porcentual, dtype: float64)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_cleaned = testing_clean.query('eficiencia_porcentual <= 100')\n",
        "testing_cleaned[testing_cleaned['eficiencia_porcentual'] > 100]['eficiencia_porcentual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4986 entries, 0 to 4990\n",
            "Data columns (total 18 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   timestamp              4986 non-null   object \n",
            " 1   turno                  4986 non-null   object \n",
            " 2   operador_id            4986 non-null   object \n",
            " 3   maquina_id             4986 non-null   object \n",
            " 4   producto_id            4986 non-null   object \n",
            " 5   temperatura            4986 non-null   float64\n",
            " 6   vibración              4986 non-null   float64\n",
            " 7   humedad                4986 non-null   float64\n",
            " 8   tiempo_ciclo           4986 non-null   float64\n",
            " 9   fallo_detectado        4986 non-null   object \n",
            " 10  tipo_fallo             495 non-null    object \n",
            " 11  cantidad_producida     4986 non-null   int64  \n",
            " 12  unidades_defectuosas   4986 non-null   int64  \n",
            " 13  eficiencia_porcentual  4986 non-null   float64\n",
            " 14  consumo_energia        4986 non-null   float64\n",
            " 15  paradas_programadas    4986 non-null   int64  \n",
            " 16  paradas_imprevistas    4986 non-null   int64  \n",
            " 17  observaciones          1483 non-null   object \n",
            "dtypes: float64(6), int64(4), object(8)\n",
            "memory usage: 740.1+ KB\n"
          ]
        }
      ],
      "source": [
        "testing_cleaned.to_csv(\"cleaned_dataset.csv\", index=False)\n",
        "testing_cleaned.info()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
